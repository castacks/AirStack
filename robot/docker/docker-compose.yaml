# desktop build
services:
  # ===================================================================================================================
  # for developing locally on a single machine
  # note, this service name is currently used as the name of the robot
  robot:
    profiles:
      - ""
      - sitl
      - simple
    extends:
      file: ./robot-base-docker-compose.yaml
      service: robot_base
    image: &desktop_image ${PROJECT_DOCKER_REGISTRY}/${PROJECT_NAME}:v${DOCKER_IMAGE_TAG}_robot-x86-64
    user: "${USER_ID:-1000}:${GROUP_ID:-1000}"
    build:
      dockerfile: ./Dockerfile.robot
      args:
        BASE_IMAGE: ubuntu:22.04
      tags:
        - *desktop_image
    # we use tmux send-keys so that the session stays alive
    command: >
      bash -c "
      service ssh restart;
      autolaunch=${AUTOLAUNCH};
      if [ $$autolaunch == 'true' ]; then
        tmux new -d -s robot_bringup;
        tmux send-keys -t robot_bringup 'bws && sws && ros2 launch ${ROBOT_LAUNCH_PACKAGE} ${ROBOT_LAUNCH_FILE}' ENTER;
      fi;
      sleep infinity"
    # assumes you're connected to work internet, so creates a network to isolate from other developers on your work internet
    networks:
      - airstack_network
    # allow scaling multiple robots on the same machine
    ports:
      # for ssh, starting from 2223-2243 on the host port all map to 22 in the container. Assumes no more than 21 robots
      - "2223-2243:22"
    # for multiple robots
    deploy:
      replicas: ${NUM_ROBOTS:-1}

  # ===================================================================================================================
  # for running on an NVIIDA jetson (linux for tegra) device
  robot-l4t:
    profiles:
      - hitl
      - deploy
    extends:
      file: ./robot-base-docker-compose.yaml
      service: robot_base
    image: &l4t_image ${PROJECT_DOCKER_REGISTRY}/${PROJECT_NAME}:v${DOCKER_IMAGE_TAG}_robot-l4t
    build:
      dockerfile: ./Dockerfile.robot
      args:
        BASE_IMAGE: nvcr.io/nvidia/l4t-jetpack:r36.4.0
        REAL_ROBOT: true
        SKIP_MACVO: true
      tags:
        - *l4t_image
    # we use tmux send-keys so that the session stays alive
    ipc: host
    command: >
      bash -c "ssh service restart;
      tmux new -d -s robot_bringup
      && tmux send-keys -t robot_bringup 
      'bws && sws && 
      DATE=$(date | sed \"s/ /_/g\" | sed \"s/:/_/g\") ros2 launch ${ROBOT_LAUNCH_PACKAGE} ${ROBOT_LAUNCH_FILE} sim:="false" ' ENTER
      && sleep infinity"
    runtime: nvidia
    # assumes network isolation via a physical router, so uses network_mode=host
    network_mode: host
    volumes:
      - /media/airlab/Storage/airstack_collection:/bags:rw

  zed-l4t:
    profiles:
      - hitl
      - deploy
    image: ${PROJECT_DOCKER_REGISTRY}/${PROJECT_NAME}:v${DOCKER_IMAGE_TAG}_zed-l4t-36-4-0
    build: 
      context: ./
      dockerfile: zed/Dockerfile.zed-l4t
      args:
        L4T_MAJOR: 36
        L4T_MINOR: 4
        L4T_PATCH: 0
    command: >
      bash -c "ssh service restart;
      tmux new -d -s zed_driver
      && tmux send-keys -t zed_driver
      'bws && sws && ros2 launch zed_wrapper zed_dual_camera.launch.py pose_cam_serial:='41591402' wire_cam_serial:='44405253' camera_name:=\"robot_1/sensors\" node_name:=\"front_stereo\" ' ENTER
      && sleep infinity"
    network_mode: host
    runtime: nvidia
    privileged: true
    ipc: host
    pid: host
    environment:
      - NVIDIA_DRIVER_CAPABILITIES=all
      - DISPLAY
      - QT_X11_NO_MITSHM=1
      - ROS_DOMAIN_ID=1
    stdin_open: true  # Equivalent to -it for interactive terminal
    tty: true  # Ensures that a pseudo-terminal is allocated
    volumes:
      - /dev:/dev 
      - /tmp:/tmp 
      - /tmp/.X11-unix:/tmp/.X11-unix
      - /var/nvidia/nvcam/settings/:/var/nvidia/nvcam/settings/
      - /etc/systemd/system/zed_x_daemon.service:/etc/systemd/system/zed_x_daemon.service
      - /usr/local/zed/resources/:/usr/local/zed/resources/
      - /usr/local/zed/settings/:/usr/local/zed/settings/
      - ./zed/ws/:/root/ros2_ws/
      - ./zed/bashrc:/root/.bashrc
      - /media/airlab/Storage/zed_svo/:/zed_svo/
      
# ===================================================================================================================
# for running tests on the robot
  robot-test:
    profiles: !override
      - "test"
    extends:
      service: robot
    command: >
      bash -il -c "
      echo 'Building and sourcing workspace...';
      bws &> /dev/null && sws &> /dev/null &&
      echo 'Starting tests for packages: takeoff_landing_planner';
      colcon test --packages-select takeoff_landing_planner --event-handlers=console_direct+;
      TEST_EXIT_CODE=$$?;
      echo \"Tests completed with exit code: $$TEST_EXIT_CODE\";
      exit $$TEST_EXIT_CODE"
