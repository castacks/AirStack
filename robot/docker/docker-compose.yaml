# desktop build
services:
  # ===================================================================================================================
  # for developing locally on a single machine
  # note, this service name is currently used as the name of the robot
  robot:
    profiles:
      - ""
      - sitl
    extends:
      file: ./robot-base-docker-compose.yaml
      service: robot_base
    image: &desktop_image ${PROJECT_DOCKER_REGISTRY}/${PROJECT_NAME}:v${DOCKER_IMAGE_TAG}_robot-x86-64
    build:
      dockerfile: ./Dockerfile.robot
      args:
        BASE_IMAGE: ubuntu:22.04
      tags:
        - *desktop_image
    # we use tmux send-keys so that the session stays alive
    command: >
      bash -c "service ssh restart;
      tmux new -d -s robot_bringup
      && tmux send-keys -t robot_bringup 
      'bws && sws && 
      ros2 launch robot_bringup robot.launch.xml' ENTER
      && sleep infinity"
    # assumes you're connected to work internet, so creates a network to isolate from other developers on your work internet
    networks:
      - airstack_network
    # allow scaling multiple robots on the same machine
    ports:
      # for ssh, starting from 2223-2243 on the host port all map to 22 in the container. Assumes no more than 21 robots
      - "2223-2243:22"

  # -------------------------------------------------------------------------------------------------------------------
  # dev container for developer debugging
  robot-dev:
    profiles: !override
      - "dev"
    extends: robot
    command: sleep infinity

  # ===================================================================================================================
  # for running on an NVIIDA jetson (linux for tegra) device
  robot-l4t:
    profiles:
      - hitl
      - deploy
    extends:
      file: ./robot-base-docker-compose.yaml
      service: robot_base
    image: &l4t_image ${PROJECT_DOCKER_REGISTRY}/${PROJECT_NAME}:v${DOCKER_IMAGE_TAG}_robot-l4t
    build:
      dockerfile: ./Dockerfile.robot
      args:
        BASE_IMAGE: nvcr.io/nvidia/l4t-jetpack:r36.4.0
        REAL_ROBOT: true
      tags:
        - *l4t_image
    # we use tmux send-keys so that the session stays alive
    ipc: host
    command: >
      bash -c "ssh service restart;
      tmux new -d -s robot_bringup
      && tmux send-keys -t robot_bringup 
      'bws && sws && 
      DATE=$(date | sed \"s/ /_/g\" | sed \"s/:/_/g\") ros2 launch robot_bringup robot.launch.xml sim:="false" ' ENTER
      && sleep infinity"
    runtime: nvidia
    # assumes network isolation via a physical router, so uses network_mode=host
    network_mode: host
    volumes:
      - /media/airlab/Storage/airstack_collection:/bags:rw

  zed-l4t:
    profiles:
      - hitl
      - deploy
    image: ${PROJECT_DOCKER_REGISTRY}/${PROJECT_NAME}:v${DOCKER_IMAGE_TAG}_zed-l4t-36-4-0
    build: 
      context: ./
      dockerfile: zed/Dockerfile.zed-l4t
      args:
        L4T_MAJOR: 36
        L4T_MINOR: 4
        L4T_PATCH: 0
    command: >
      bash -c "sleep infinity"
    network_mode: host
    runtime: nvidia
    privileged: true
    ipc: host
    pid: host
    environment:
      - NVIDIA_DRIVER_CAPABILITIES=all
      - DISPLAY
      - QT_X11_NO_MITSHM=1
      - ROS_DOMAIN_ID=2
    stdin_open: true  # Equivalent to -it for interactive terminal
    tty: true  # Ensures that a pseudo-terminal is allocated
    volumes:
      - /dev:/dev 
      - /tmp:/tmp 
      - /tmp/.X11-unix:/tmp/.X11-unix
      - /var/nvidia/nvcam/settings/:/var/nvidia/nvcam/settings/
      - /etc/systemd/system/zed_x_daemon.service:/etc/systemd/system/zed_x_daemon.service
      - /usr/local/zed/resources/:/usr/local/zed/resources/
      - /usr/local/zed/settings/:/usr/local/zed/settings/
      - ./zed/ws/:/root/ros2_ws/
      - ./zed/bashrc:/root/.bashrc
      - /media/airlab/Storage/zed_svo/:/zed_svo/